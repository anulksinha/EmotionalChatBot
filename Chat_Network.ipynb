{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation, Embedding, TimeDistributed, concatenate, Input\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import word2vec_utils as w2v\n",
    "import data\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from data_utils import split_dataset \n",
    "from chat_constants import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model = w2v.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def null_punisher(y_true, y_pred ):\n",
    "    '''Provides stronger incentive to avoid Null'''\n",
    "    L = 3\n",
    "    error = keras.losses.cosine_proximity( y_true,y_pred)\n",
    "    if y_true[-1] != BLANK[-1] or y_pred[-1] == BLANK[-1]:\n",
    "        error *= L\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSTM_DROPOUT = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A1_input = Input(shape=(MAX_SENT_LENGTH,EMBED_DIM))\n",
    "\n",
    "A1_layer1 = LSTM(EMBED_DIM - 26,name = \"A1_layer1\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "A1_layer2 = LSTM(EMBED_DIM - 51,name = \"A1_layer2\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "A1_net = A1_layer2(A1_layer1(A1_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B_input = Input(shape=(MAX_SENT_LENGTH,EMBED_DIM))\n",
    "\n",
    "B_layer1 = LSTM(EMBED_DIM-25,name = \"B_layer1\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "B_layer2 = LSTM(EMBED_DIM-50,name = \"B_layer2\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "\n",
    "B_net = B_layer2(B_layer1(B_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_8 (InputLayer)             (None, 30, 101)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_9 (InputLayer)             (None, 30, 101)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "A1_layer1 (LSTM)                 (None, 30, 75)        53100                                        \n",
      "____________________________________________________________________________________________________\n",
      "B_layer1 (LSTM)                  (None, 30, 76)        54112                                        \n",
      "____________________________________________________________________________________________________\n",
      "A1_layer2 (LSTM)                 (None, 30, 50)        25200                                        \n",
      "____________________________________________________________________________________________________\n",
      "B_layer2 (LSTM)                  (None, 30, 51)        26112                                        \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 30, 101)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "A2_layer1 (LSTM)                 (None, 30, 101)       82012                                        \n",
      "____________________________________________________________________________________________________\n",
      "A2_layer2 (LSTM)                 (None, 30, 101)       82012                                        \n",
      "====================================================================================================\n",
      "Total params: 322,548\n",
      "Trainable params: 322,548\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combined = concatenate([A1_net,B_net])\n",
    "A2_pred1 = LSTM(EMBED_DIM, name = \"A2_layer1\", return_sequences = True, dropout = LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "A2_pred2 = LSTM(EMBED_DIM, name = \"A2_layer2\", return_sequences = True, dropout = LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "#A2_pred3 = LSTM(EMBED_DIM, name = \"A2_layer3\", return_sequences = True, dropout = LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "\n",
    "A2_net =A2_pred2(A2_pred1(combined))\n",
    "\n",
    "chat_model = Model(inputs = [ A1_input,B_input], outputs = [A2_net])\n",
    "chat_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint( 'chat_net.h5',verbose = 1,monitor = 'val_acc',save_best_only = True)\n",
    "early_stopping = EarlyStopping( monitor = 'val_acc',patience = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1, B, A2 = data.load_data()\n",
    "All_data = np.array([A1,B,A2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "[A1_set1,B_set1,A2_set1] = All_data[:,0:8000]\n",
    "[A1_set2,B_set2,A2_set2] = All_data[:,8000:16000]\n",
    "[A1_set3,B_set3,A2_set3] = All_data[:,16000:24000]\n",
    "[A1_set4,B_set4,A2_set4] = All_data[:,24000:]\n",
    "sets = [[A1_set1,B_set1,A2_set1],[A1_set2,B_set2,A2_set2],[A1_set3,B_set3,A2_set3],[A1_set4,B_set4,A2_set4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr = 0.0015)\n",
    "chat_model.compile( optimizer=adam,loss = null_punisher,metrics = ['accuracy'])\n",
    "chat_model.load_weights('chat_net.h5',by_name = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7600 samples, validate on 400 samples\n",
      "Epoch 1/3\n",
      "7000/7600 [==========================>...] - ETA: 7s - loss: -0.0128 - acc: 0.3582 "
     ]
    }
   ],
   "source": [
    "for a1,b,a2 in sets:\n",
    "    A1_train,B_train,A2_train = w2v.get_training_data(a1,b,a2)\n",
    "    chat_model.fit([A1_train,B_train], A2_train,\n",
    "          batch_size=200, epochs=3,\n",
    "          validation_split = 0.05,\n",
    "          callbacks = [checkpointer,early_stopping] )\n",
    "    #chat_model.save('chat_net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def just_model_un_vectorize( predicted ):\n",
    "    ret =[]\n",
    "    for word_vec in predicted:\n",
    "        if abs(word_vec[-1] - 1) < 0.001:\n",
    "            ret.append(\"_\")\n",
    "            continue\n",
    "        word_vec = word_vec[:-1]\n",
    "        x = w2v_model.similar_by_vector( word_vec, topn = 3 )\n",
    "        print( x )\n",
    "        w2v_word,w2v_similarity = x[0]\n",
    "        print( w2v_word, \" \", w2v_similarity )\n",
    "        ret.append(w2v_word)\n",
    "    return( \" \".join(ret) )\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_test_sentence():\n",
    "    index = random.randint(0,len(A1)-1)\n",
    "    print A2[index]\n",
    "    return( w2v.get_training_data(A1[index:index+1],B[index:index+1],A2[index:index+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 7 2 @ Would you please see if Sandro is with him ? He's not in his room . I'm sorry to disturb you .\n"
     ]
    }
   ],
   "source": [
    "A1_test,B_test,A2_test = get_random_test_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v.unvectorize_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = chat_model.predict([A1_test,B_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'1', 0.9793657064437866), (u'2', 0.7656130194664001), (u'4', 0.5564773082733154)]\n",
      "(u'1', ' ', 0.9793657064437866)\n",
      "[(u'9', 0.8987573385238647), (u'8', 0.8393089771270752), (u'7', 0.6883097887039185)]\n",
      "(u'9', ' ', 0.8987573385238647)\n",
      "[(u'1', 0.9815201163291931), (u'2', 0.7573592662811279), (u'4', 0.5622636079788208)]\n",
      "(u'1', ' ', 0.9815201163291931)\n",
      "[(u'@', 0.9998001456260681), (u'1', 0.5307570099830627), (u'Ears', 0.48693588376045227)]\n",
      "(u'@', ' ', 0.9998001456260681)\n",
      "[(u'You', 0.7442670464515686), (u'But', 0.7287113666534424), (u'Well', 0.684301495552063)]\n",
      "(u'You', ' ', 0.7442670464515686)\n",
      "[(u'.', 0.9013633728027344), (u',', 0.8703750371932983), (u'--', 0.69184809923172)]\n",
      "(u'.', ' ', 0.9013633728027344)\n",
      "[(u'.', 0.8808210492134094), (u',', 0.8138697147369385), (u'you', 0.7223097085952759)]\n",
      "(u'.', ' ', 0.8808210492134094)\n",
      "[(u'.', 0.9075521230697632), (u',', 0.8332178592681885), (u'that', 0.6965234279632568)]\n",
      "(u'.', ' ', 0.9075521230697632)\n",
      "[(u'.', 0.9146542549133301), (u',', 0.8310866355895996), (u'that', 0.6979981660842896)]\n",
      "(u'.', ' ', 0.9146542549133301)\n",
      "[(u'.', 0.9240490198135376), (u',', 0.8321719169616699), (u'that', 0.6909051537513733)]\n",
      "(u'.', ' ', 0.9240490198135376)\n",
      "[(u'.', 0.9283543825149536), (u',', 0.8307482600212097), (u'that', 0.6870230436325073)]\n",
      "(u'.', ' ', 0.9283543825149536)\n",
      "[(u'.', 0.9304161071777344), (u',', 0.8296365737915039), (u'that', 0.6845991015434265)]\n",
      "(u'.', ' ', 0.9304161071777344)\n",
      "[(u'.', 0.9310896992683411), (u',', 0.8283104300498962), (u'that', 0.6838730573654175)]\n",
      "(u'.', ' ', 0.9310896992683411)\n",
      "[(u'.', 0.9316022396087646), (u',', 0.8283368349075317), (u'that', 0.6829985976219177)]\n",
      "(u'.', ' ', 0.9316022396087646)\n",
      "[(u'.', 0.9318748712539673), (u',', 0.8286638855934143), (u'that', 0.6825141310691833)]\n",
      "(u'.', ' ', 0.9318748712539673)\n",
      "1 9 1 @ You . . . . . . . . . . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n"
     ]
    }
   ],
   "source": [
    "predicted_words = just_model_un_vectorize( predicted[0] )\n",
    "print( predicted_words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u',', 0.8113983869552612),\n",
       " (u'--', 0.5987824201583862),\n",
       " (u'GALLERY', 0.5957099199295044),\n",
       " (u'charts', 0.5932552814483643),\n",
       " (u'hellhole', 0.5896182656288147),\n",
       " (u'Ears', 0.5814112424850464),\n",
       " (u'contributions', 0.5766328573226929),\n",
       " (u'Underworld', 0.5752488970756531),\n",
       " (u'GAP', 0.5732450485229492),\n",
       " (u'and', 0.5639781951904297)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = {}\n",
    "a['__BLANK__'] = BLANK\n",
    "a['__BLANK__']\n",
    "\n",
    "import pickle\n",
    "with open('unknown_words_stored.pkl', 'w+') as f:\n",
    "    pickle.dump(a, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1 9 1 @ Yes I am .', '1 9 1 @ What are you doing ?', '1 9 1 @ Nothing .')\n"
     ]
    }
   ],
   "source": [
    "print( A1[30000], B[30000],A2[30000] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'woman', 0.7161317467689514),\n",
       " (u'guy', 0.6970781087875366),\n",
       " (u'warrior', 0.6738820672035217),\n",
       " (u'fellow', 0.6728172302246094),\n",
       " (u'hero', 0.6715325117111206),\n",
       " (u'boy', 0.6687963008880615),\n",
       " (u'lady', 0.6600995063781738),\n",
       " (u'cat', 0.656214714050293),\n",
       " (u'person', 0.6318941116333008),\n",
       " (u'kid', 0.6249631643295288)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.similar_by_word(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106455"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32269,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AB_Input = Input(shape =(MAX_SENT_LENGTH,EMBED_DIM))\n",
    "\n",
    "AB_layer1 = LSTM(EMBED_DIM,return_sequences=True, name = \"AB_layer1\", dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "AB_layer2 = LSTM(EMBED_DIM,return_sequences=True, name = \"AB_layer2\", dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "AB_layer3 = LSTM(EMBED_DIM,return_sequences=True, name = \"AB_layer3\", dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "\n",
    "AB_output = AB_layer3(AB_layer2(AB_layer1(AB_Input)))\n",
    "\n",
    "chat_model = Model(inputs = [ AB_Input], outputs = [AB_output])\n",
    "chat_model.compile(loss=null_punisher,\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "early_stopping = EarlyStopping( monitor = 'val_acc',patience = 2)\n",
    "chat_model.load_weights('chat_net.h5',by_name=True)\n",
    "chat_model.fit([A1B_train], A2_train,\n",
    "          batch_size=200, epochs=20,\n",
    "          validation_split = 0.025 )\n",
    "chat_model.save('chat_net.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
