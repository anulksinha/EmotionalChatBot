{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation, Embedding, TimeDistributed, concatenate, Input\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import word2vec_utils as w2v\n",
    "import data\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from data_utils import split_dataset \n",
    "from chat_constants import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model = w2v.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def null_punisher(y_true, y_pred ):\n",
    "    '''Provides stronger incentive to avoid Null'''\n",
    "    L = 3\n",
    "    error = keras.losses.cosine_proximity( y_true,y_pred)\n",
    "    if y_true[-1] != BLANK[-1] or y_pred[-1] == BLANK[-1]:\n",
    "        error *= L\n",
    "    return error\n",
    "\n",
    "def get_sets_of_data(size=5000):\n",
    "    A1, B, A2 = data.load_data()\n",
    "    All_data = np.array([A1,B,A2])\n",
    "    num_sections = len(A1)//size\n",
    "    sets = []\n",
    "    for i in range(num_sections):\n",
    "        sets.append(All_data[:,i*size:(i+1)*size])\n",
    "    return(sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSTM_DROPOUT = 0.15\n",
    "A1, B, A2 = data.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A1_input = Input(shape=(MAX_SENT_LENGTH,EMBED_DIM))\n",
    "\n",
    "A1_layer1 = LSTM(EMBED_DIM - 26,name = \"A1_layer1\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "A1_layer2 = LSTM(EMBED_DIM - 51,name = \"A1_layer2\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "A1_net = A1_layer2(A1_layer1(A1_input))\n",
    "\n",
    "B_input = Input(shape=(MAX_SENT_LENGTH,EMBED_DIM))\n",
    "\n",
    "B_layer1 = LSTM(EMBED_DIM-25,name = \"B_layer1\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "B_layer2 = LSTM(EMBED_DIM-50,name = \"B_layer2\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "\n",
    "B_net = B_layer2(B_layer1(B_input))\n",
    "\n",
    "combined = concatenate([A1_net,B_net])\n",
    "A2_pred1 = LSTM(EMBED_DIM, name = \"A2_layer1\", return_sequences = True, dropout = LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "A2_pred2 = LSTM(EMBED_DIM, name = \"A2_layer2\", return_sequences = True, dropout = LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "#A2_pred3 = LSTM(EMBED_DIM, name = \"A2_layer3\", return_sequences = True, dropout = LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "\n",
    "A2_net =A2_pred2(A2_pred1(combined))\n",
    "\n",
    "chat_model = Model(inputs = [ A1_input,B_input], outputs = [A2_net])\n",
    "chat_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint( 'chat_net.h5',verbose = 1,monitor = 'val_acc',save_best_only = True)\n",
    "early_stopping = EarlyStopping( monitor = 'val_acc',patience = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr = 0.0015)\n",
    "chat_model.compile( optimizer=adam,loss = null_punisher,metrics = ['accuracy'])\n",
    "chat_model.load_weights('chat_net.h5',by_name = True)\n",
    "for a1,b,a2 in sets:\n",
    "    A1_train,B_train,A2_train = w2v.get_training_data(a1,b,a2)\n",
    "    chat_model.fit([A1_train,B_train], A2_train,\n",
    "          batch_size=200, epochs=3,\n",
    "          validation_split = 0.05,\n",
    "          callbacks = [checkpointer,early_stopping] )\n",
    "    #chat_model.save('chat_net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def just_model_un_vectorize( predicted ):\n",
    "    ret =[]\n",
    "    for word_vec in predicted:\n",
    "        if abs(word_vec[-1] - 1) < 0.001:\n",
    "            ret.append(\"_\")\n",
    "            continue\n",
    "        word_vec = word_vec[:-1]\n",
    "        x = w2v_model.similar_by_vector( word_vec, topn = 3 )\n",
    "        print( x )\n",
    "        w2v_word,w2v_similarity = x[0]\n",
    "        print( w2v_word, \" \", w2v_similarity )\n",
    "        ret.append(w2v_word)\n",
    "    return( \" \".join(ret) )\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_test_sentence():\n",
    "    index = random.randint(0,len(A1)-1)\n",
    "    print A2[index]\n",
    "    return( w2v.get_training_data(A1[index:index+1],B[index:index+1],A2[index:index+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A1_test,B_test,A2_test = get_random_test_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v.unvectorize_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = chat_model.predict([A1_test,B_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_words = just_model_un_vectorize( predicted[0] )\n",
    "print( predicted_words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model.most_similar('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = {}\n",
    "a['__BLANK__'] = BLANK\n",
    "a['__BLANK__']\n",
    "\n",
    "import pickle\n",
    "with open('unknown_words_stored.pkl', 'w+') as f:\n",
    "    pickle.dump(a, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print( A1[30000], B[30000],A2[30000] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model.similar_by_word(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AB_Input = Input(shape =(MAX_SENT_LENGTH,EMBED_DIM))\n",
    "\n",
    "AB_layer1 = LSTM(EMBED_DIM,return_sequences=True, name = \"AB_layer1\", dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "AB_layer2 = LSTM(EMBED_DIM,return_sequences=True, name = \"AB_layer2\", dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "AB_layer3 = LSTM(EMBED_DIM,return_sequences=True, name = \"AB_layer3\", dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "\n",
    "AB_output = AB_layer3(AB_layer2(AB_layer1(AB_Input)))\n",
    "\n",
    "chat_model = Model(inputs = [ AB_Input], outputs = [AB_output])\n",
    "chat_model.compile(loss=null_punisher,\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "early_stopping = EarlyStopping( monitor = 'val_acc',patience = 2)\n",
    "chat_model.load_weights('chat_net.h5',by_name=True)\n",
    "chat_model.fit([A1B_train], A2_train,\n",
    "          batch_size=200, epochs=20,\n",
    "          validation_split = 0.025 )\n",
    "chat_model.save('chat_net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_input = Input(shape=(MAX_SENT_LENGTH,EMBED_DIM))\n",
    "\n",
    "layer1 = Bidirectional(LSTM(EMBED_DIM,name = \"layer1\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT))\n",
    "layer2 = Bidirectional(LSTM(EMBED_DIM,name = \"layer2\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT))\n",
    "layer3 = LSTM(EMBED_DIM,name = \"layer3\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "\n",
    "my_output = layer3(layer2(layer1(my_input)))\n",
    "\n",
    "simpl_chat_model = Model(inputs = [ my_input], outputs = [my_output])\n",
    "simpl_chat_model.summary()\n",
    "\n",
    "simpl_checkpointer = ModelCheckpoint( 'simpl_chat_net.h5',verbose = 1,monitor = 'val_acc',save_best_only = True)\n",
    "simpl_early_stopping = EarlyStopping( monitor = 'val_acc',patience = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr = 0.02)\n",
    "simpl_chat_model.compile( optimizer=adam,loss = null_punisher,metrics = ['accuracy'])\n",
    "#simpl_chat_model.load_weights('simpl_chat_net.h5',by_name = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for a1,b,a2 in sets:\n",
    "    A1_train,B_train,A2_train = w2v.get_training_data(a1,b,a2)\n",
    "    simpl_chat_model.fit([A1_train], B_train,\n",
    "          batch_size=200, epochs=1,\n",
    "          validation_split = 0.05,\n",
    "          callbacks = [simpl_checkpointer,simpl_early_stopping] )\n",
    "    simpl_chat_model.fit([B_train], A2_train,\n",
    "          batch_size=200, epochs=1,\n",
    "          validation_split = 0.05,\n",
    "          callbacks = [simpl_checkpointer,simpl_early_stopping] )\n",
    "    #chat_model.save('chat_net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predit = simpl_chat_model.predict([B_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_words = just_model_un_vectorize( predit[0] )\n",
    "print( predicted_words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, 30, 101)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (None, 30, 101)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional)  (None, 30, 202)       164024                                       \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional)  (None, 30, 202)       164024                                       \n",
      "____________________________________________________________________________________________________\n",
      "A1_layer2 (LSTM)                 (None, 30, 202)       327240                                       \n",
      "____________________________________________________________________________________________________\n",
      "B_layer2 (LSTM)                  (None, 30, 202)       327240                                       \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 30, 404)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "A2_layer1 (LSTM)                 (None, 30, 404)       1307344                                      \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistribu (None, 30, 10003)     4051215                                      \n",
      "====================================================================================================\n",
      "Total params: 6,341,087\n",
      "Trainable params: 6,341,087\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "############### One Hot ####################\n",
    "A1_input = Input(shape=(MAX_SENT_LENGTH,EMBED_DIM))\n",
    "\n",
    "A1_layer1 = Bidirectional( LSTM(EMBED_DIM,name = \"A1_layer1\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT) )\n",
    "A1_layer2 = LSTM(EMBED_DIM*2,name = \"A1_layer2\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "A1_net = A1_layer2(A1_layer1(A1_input))\n",
    "\n",
    "B_input = Input(shape=(MAX_SENT_LENGTH,EMBED_DIM))\n",
    "\n",
    "B_layer1 = Bidirectional( LSTM(EMBED_DIM,name = \"B_layer1\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT) )\n",
    "B_layer2 = LSTM(EMBED_DIM*2,name = \"B_layer2\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "\n",
    "B_net = B_layer2(B_layer1(B_input))\n",
    "\n",
    "combined = concatenate([A1_net,B_net])\n",
    "A2_pred1 = LSTM(EMBED_DIM*4, name = \"A2_layer1\", return_sequences = True, dropout = LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "A2_pred2 = TimeDistributed(Dense(VOCAB_SIZE + 3, name = \"A2_layer2\", activation = 'softmax' ) )\n",
    "\n",
    "A2_net =A2_pred2(A2_pred1(combined))\n",
    "\n",
    "one_hot_chat_model = Model(inputs = [ A1_input,B_input], outputs = [A2_net])\n",
    "one_hot_chat_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint( 'one_hot_chat_net.h5',verbose = 1,monitor = 'val_acc',save_best_only = True)\n",
    "early_stopping = EarlyStopping( monitor = 'val_acc',patience = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sets = get_sets_of_data(size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 950 samples, validate on 50 samples\n",
      "Epoch 1/3\n",
      "940/950 [============================>.] - ETA: 0s - loss: 4.5295 - acc: 0.4367Epoch 00000: val_acc improved from -inf to 0.47133, saving model to one_hot_chat_net.h5\n",
      "950/950 [==============================] - 79s - loss: 4.5380 - acc: 0.4358 - val_loss: 4.2251 - val_acc: 0.4713\n",
      "Epoch 2/3\n",
      "940/950 [============================>.] - ETA: 0s - loss: 4.0254 - acc: 0.4845Epoch 00001: val_acc did not improve\n",
      "950/950 [==============================] - 78s - loss: 4.0265 - acc: 0.4844 - val_loss: 4.0221 - val_acc: 0.4713\n",
      "Epoch 3/3\n",
      "940/950 [============================>.] - ETA: 0s - loss: 3.9485 - acc: 0.4917Epoch 00002: val_acc did not improve\n",
      "950/950 [==============================] - 75s - loss: 3.9432 - acc: 0.4919 - val_loss: 3.9506 - val_acc: 0.4713\n"
     ]
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(lr = 0.01)#default 0.001\n",
    "one_hot_chat_model.compile( optimizer=adam,loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "#chat_model.load_weights('one_hot_chat_net.h5',by_name = True)\n",
    "for a1,b,a2 in sets:\n",
    "    A1_train,B_train,A2_train = w2v.get_training_data_one_hot_out(a1,b,a2)\n",
    "    cat_a2 = []\n",
    "    for sent in A2_train:\n",
    "        cat_a2.append(to_categorical(sent,num_classes = VOCAB_SIZE + 3))\n",
    "    cat_a2 = np.array(cat_a2)\n",
    "    one_hot_chat_model.fit([A1_train,B_train], cat_a2,\n",
    "          batch_size=20, epochs=3,\n",
    "          validation_split = 0.05,\n",
    "          callbacks = [checkpointer,early_stopping] )\n",
    "    one_hot_chat_model.save('one_hot_chat_net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_vectorize( sentence, pad_length = -1, word_freqs = None ):\n",
    "    if word_freqs is None:\n",
    "        word_freqs = np.load('words_in_order_of_freq.npy')\n",
    "    \n",
    "    sentence = split_sentence( sentence )\n",
    "    words = sentence.split(\" \")\n",
    "    vectorized_sentence = []\n",
    "    \n",
    "    for word in words:\n",
    "        lower_word = word.lower()\n",
    "        number = word_freqs.index(lower_word)\n",
    "        if number > VOCAB_SIZE:\n",
    "            number = UNK\n",
    "        vectorized_sentence.append( number )\n",
    "\n",
    "    if( pad_length != -1 ):\n",
    "        while( len(vectorized_sentence) < pad_length ):\n",
    "            vectorized_sentence.append(NULL)\n",
    "    \n",
    "    return np.array(vectorized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(np.array([UNK]),num_classes = VOCAB_SIZE + 2 )["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 10003)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(A2_train[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 10003)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 30)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 30, 10003)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_a2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
