{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation, Embedding, TimeDistributed, Concatenate, Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "import word2vec_utils as w2v\n",
    "import data\n",
    "import numpy as np\n",
    "import re\n",
    "from data_utils import split_dataset \n",
    "from chat_constants import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = w2v.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A1, B, A2 = data.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A1_train,B_train,A2_train = w2v.get_n_training_data(20000,A1,B,A2)\n",
    "A1B_train = np.concatenate((A1_train,B_train),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def null_punisher(y_true, y_pred ):\n",
    "    '''Provides stronger incentive to avoid Null'''\n",
    "    L = 3\n",
    "    error = keras.losses.cosine_proximity( y_true,y_pred)\n",
    "    if y_true != BLANK:\n",
    "        error *= L\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSTM_DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A1_input = Input(shape=(MAX_SENT_LENGTH,EMBED_DIM))\n",
    "\n",
    "A1_layer1 = LSTM(EMBED_DIM,return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "A1 = A1_layer1(A1_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B_input = Input(shape=(MAX_SENT_LENGTH,EMBED_DIM))\n",
    "\n",
    "B_layer1 = LSTM(EMBED_DIM,return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "B = B_layer1(B_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = Concatenate([A1,B])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AB_Input = Input(shape =(MAX_SENT_LENGTH*2,EMBED_DIM))\n",
    "\n",
    "AB_layer1 = LSTM(EMBED_DIM,return_sequences=True, name = \"AB_layer1\", dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "AB_layer2 = LSTM(EMBED_DIM,return_sequences=True, name = \"AB_layer2\", dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "AB_layer3 = LSTM(EMBED_DIM,return_sequences=True, name = \"AB_layer3\", dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "\n",
    "AB_output = AB_layer3(AB_layer2(AB_layer1(AB_Input)))\n",
    "\n",
    "chat_model = Model(inputs = [ AB_Input], outputs = [AB_output])\n",
    "chat_model.compile(loss=null_punisher,\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "early_stopping = EarlyStopping( monitor = 'val_acc',patience = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19500 samples, validate on 500 samples\n",
      "Epoch 1/20\n",
      "19500/19500 [==============================] - 785s - loss: -0.0098 - acc: 0.8399 - val_loss: -0.0099 - val_acc: 0.8833\n",
      "Epoch 2/20\n",
      "19500/19500 [==============================] - 1081s - loss: -0.0099 - acc: 0.8843 - val_loss: -0.0099 - val_acc: 0.9500\n",
      "Epoch 3/20\n",
      "19500/19500 [==============================] - 1644s - loss: -0.0099 - acc: 0.9070 - val_loss: -0.0099 - val_acc: 0.9667\n",
      "Epoch 4/20\n",
      "19500/19500 [==============================] - 1811s - loss: -0.0099 - acc: 0.9171 - val_loss: -0.0099 - val_acc: 0.9667\n",
      "Epoch 5/20\n",
      "19500/19500 [==============================] - 2031s - loss: -0.0099 - acc: 0.9234 - val_loss: -0.0099 - val_acc: 0.9833\n",
      "Epoch 6/20\n",
      "19500/19500 [==============================] - 1982s - loss: -0.0099 - acc: 0.9287 - val_loss: -0.0099 - val_acc: 0.9667\n",
      "Epoch 7/20\n",
      "19500/19500 [==============================] - 1972s - loss: -0.0099 - acc: 0.9333 - val_loss: -0.0099 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "19500/19500 [==============================] - 1896s - loss: -0.0099 - acc: 0.9366 - val_loss: -0.0099 - val_acc: 0.9833\n",
      "Epoch 9/20\n",
      "19500/19500 [==============================] - 1797s - loss: -0.0099 - acc: 0.9394 - val_loss: -0.0099 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "19500/19500 [==============================] - 1909s - loss: -0.0099 - acc: 0.9418 - val_loss: -0.0099 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "19500/19500 [==============================] - 1944s - loss: -0.0099 - acc: 0.9432 - val_loss: -0.0099 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "19500/19500 [==============================] - 1928s - loss: -0.0099 - acc: 0.9447 - val_loss: -0.0099 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "19500/19500 [==============================] - 1880s - loss: -0.0099 - acc: 0.9459 - val_loss: -0.0099 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "19500/19500 [==============================] - 1871s - loss: -0.0099 - acc: 0.9470 - val_loss: -0.0099 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "19500/19500 [==============================] - 1814s - loss: -0.0099 - acc: 0.9480 - val_loss: -0.0099 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "19500/19500 [==============================] - 1761s - loss: -0.0099 - acc: 0.9492 - val_loss: -0.0099 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "19500/19500 [==============================] - 1715s - loss: -0.0099 - acc: 0.9499 - val_loss: -0.0099 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "19500/19500 [==============================] - 1705s - loss: -0.0099 - acc: 0.9507 - val_loss: -0.0099 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "19500/19500 [==============================] - 1657s - loss: -0.0099 - acc: 0.9515 - val_loss: -0.0099 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "19500/19500 [==============================] - 1628s - loss: -0.0099 - acc: 0.9523 - val_loss: -0.0099 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "chat_model.load_weights('chat_net.h5',by_name=True)\n",
    "chat_model.fit([A1B_train], A2_train,\n",
    "          batch_size=200, epochs=20,\n",
    "          validation_split = 0.025 )\n",
    "chat_model.save('chat_net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.05078125 -0.09326172  0.06494141 ..., -0.04150391  0.00817871  0.        ]\n",
      "  [ 0.140625   -0.02722168  0.03295898 ..., -0.08935547  0.10205078  0.        ]\n",
      "  [ 0.05078125 -0.09326172  0.06494141 ..., -0.04150391  0.00817871  0.        ]\n",
      "  ..., \n",
      "  [ 0.          0.          0.         ...,  0.          0.          1.        ]\n",
      "  [ 0.          0.          0.         ...,  0.          0.          1.        ]\n",
      "  [ 0.          0.          0.         ...,  0.          0.          1.        ]]\n",
      "\n",
      " [[ 0.05078125 -0.09326172  0.06494141 ..., -0.04150391  0.00817871  0.        ]\n",
      "  [ 0.140625   -0.02722168  0.03295898 ..., -0.08935547  0.10205078  0.        ]\n",
      "  [ 0.05078125 -0.09326172  0.06494141 ..., -0.04150391  0.00817871  0.        ]\n",
      "  ..., \n",
      "  [ 0.          0.          0.         ...,  0.          0.          1.        ]\n",
      "  [ 0.          0.          0.         ...,  0.          0.          1.        ]\n",
      "  [ 0.          0.          0.         ...,  0.          0.          1.        ]]]\n"
     ]
    }
   ],
   "source": [
    "chat_model.load_weights('chat_net.h5',by_name=True)\n",
    "\n",
    "A1_test,B_test,A2_test = w2v.get_n_training_data(2,A1[10000:],B[10000:],A2[10000:])\n",
    "A1B_test = np.concatenate((A1_test,B_test),axis=1)\n",
    "print A1B_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v.unvectorize_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = chat_model.predict(A1B_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('w2v word-score', u'1', 0.9980672597885132, '\\n', 'uk word-score', 'a', 0.056033043745772247)\n",
      "('w2v word-score', u'@', 0.9984095692634583, '\\n', 'uk word-score', 'break-', 0.052939259401523289)\n",
      "('w2v word-score', u'Not', 0.9968540668487549, '\\n', 'uk word-score', 'and', 0.082096403343257435)\n",
      "('w2v word-score', u'the', 0.9954041242599487, '\\n', 'uk word-score', 'a', 0.072104772078892515)\n",
      "('w2v word-score', u'hacking', 0.9770256876945496, '\\n', 'uk word-score', 'to', 0.076789168099464206)\n",
      "('w2v word-score', u'Darmer', 0.315388947725296, '\\n', 'uk word-score', 'and', 0.97905361822752179)\n",
      "('w2v word-score', u'gagging', 0.8061763048171997, '\\n', 'uk word-score', 'and', 0.5102656647626258)\n",
      "('w2v word-score', u'Regal_Beagle', 0.31222817301750183, '\\n', 'uk word-score', 'and', 0.96898525661626256)\n",
      "('w2v word-score', u'spitting', 0.9452880620956421, '\\n', 'uk word-score', 'and', 0.23605261754542997)\n",
      "('w2v word-score', u'part', 0.9399054050445557, '\\n', 'uk word-score', '.', 0.16153080103069159)\n",
      "('w2v word-score', u'stablemasters', 0.2521167993545532, '\\n', 'uk word-score', '.', 0.94980680968755216)\n",
      "('w2v word-score', u'Please', 0.7800537347793579, '\\n', 'uk word-score', '.', 0.33050476358264885)\n",
      "('w2v word-score', u'Escovedo', 0.2515993118286133, '\\n', 'uk word-score', '.', 0.94833911788477876)\n",
      "('w2v word-score', u'Stones', 0.2640480697154999, '\\n', 'uk word-score', '.', 0.66693084777398515)\n",
      "('w2v word-score', u'Stones', 0.26274794340133667, '\\n', 'uk word-score', '.', 0.64330988315437654)\n",
      "('w2v word-score', u'Thomas_Eakins_masterpiece', 0.2609696090221405, '\\n', 'uk word-score', '.', 0.73031849984655095)\n",
      "('w2v word-score', u'Escovedo', 0.27731770277023315, '\\n', 'uk word-score', '.', 0.76920363240902667)\n",
      "('w2v word-score', u'unrecouped', 0.25573599338531494, '\\n', 'uk word-score', '.', 0.6133006643454022)\n",
      "('w2v word-score', u'spitting', 0.2518787980079651, '\\n', 'uk word-score', '.', 0.54381164794955095)\n",
      "('w2v word-score', u'part', 0.2898973524570465, '\\n', 'uk word-score', '.', 0.64707168413567973)\n",
      "('w2v word-score', u'La_Finca', 0.2576155662536621, '\\n', 'uk word-score', '.', 0.73882694330097332)\n",
      "('w2v word-score', u'Escovedo', 0.3003111779689789, '\\n', 'uk word-score', '.', 0.72156313912462822)\n",
      "('w2v word-score', u'Minolta_camera', 0.2793729305267334, '\\n', 'uk word-score', '.', 0.4998956985140936)\n",
      "('w2v word-score', u'Sectarian_violence_periodically', 0.25563251972198486, '\\n', 'uk word-score', '.', 0.15334926546893182)\n",
      "('w2v word-score', u'bloodless_putsch', 0.2619220018386841, '\\n', 'uk word-score', '.', 0.11899012658364337)\n",
      "2 8 1 @ Not the hacking and gagging and spitting part . Please . . . . . . . . . . . Sectarian_violence_periodically bloodless_putsch _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n"
     ]
    }
   ],
   "source": [
    "predicted_words = w2v.unvectorize_sentence( predicted[0] )\n",
    "print( predicted_words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.92014e-06\n",
      "4.56457e-05\n",
      "0.000285789\n",
      "0.000822868\n",
      "0.00136276\n",
      "0.00204014\n",
      "0.00225027\n",
      "-0.000994075\n",
      "-0.00131872\n",
      "-0.00209939\n",
      "-0.0021074\n",
      "-0.00377722\n",
      "-0.00487315\n",
      "-0.000230759\n",
      "0.108067\n",
      "0.724087\n",
      "0.939856\n",
      "0.9877\n",
      "0.996966\n",
      "0.968217\n",
      "0.865467\n",
      "0.803786\n",
      "0.839297\n",
      "0.99998\n",
      "0.999996\n",
      "0.999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for word in predicted[0]:\n",
    "    print word[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {}\n",
    "a['__BLANK__'] = BLANK\n",
    "a['__BLANK__']\n",
    "\n",
    "import pickle\n",
    "with open('unknown_words_stored.pkl', 'w+') as f:\n",
    "    pickle.dump(a, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1 9 1 @ Yes I am .', '1 9 1 @ What are you doing ?', '1 9 1 @ Nothing .')\n"
     ]
    }
   ],
   "source": [
    "print( A1[30000], B[30000],A2[30000] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(A1_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106455"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-43f6c2051f64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'A2' is not defined"
     ]
    }
   ],
   "source": [
    "A2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
