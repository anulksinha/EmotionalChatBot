{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation, Embedding, TimeDistributed, concatenate, Input\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import word2vec_utils as w2v\n",
    "import data\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from data_utils import split_dataset \n",
    "from chat_constants import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model = w2v.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def null_punisher(y_true, y_pred ):\n",
    "    '''Provides stronger incentive to avoid Null'''\n",
    "    L = 3\n",
    "    error = keras.losses.cosine_proximity( y_true,y_pred)\n",
    "    if y_true[-1] != BLANK[-1] or y_pred[-1] == BLANK[-1]:\n",
    "        error *= L\n",
    "    return error\n",
    "\n",
    "def get_sets_of_data(size=5000):\n",
    "    A1, B, A2 = data.load_data()\n",
    "    All_data = np.array([A1,B,A2])\n",
    "    num_sections = len(A1)//size\n",
    "    sets = []\n",
    "    for i in range(num_sections):\n",
    "        sets.append(All_data[:,i*size:(i+1)*size])\n",
    "    return(sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSTM_DROPOUT = 0.15\n",
    "A1, B, A2 = data.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A1_input = Input(shape=(MAX_SENT_LENGTH,EMBED_DIM))\n",
    "\n",
    "A1_layer1 = LSTM(EMBED_DIM - 26,name = \"A1_layer1\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "A1_layer2 = LSTM(EMBED_DIM - 51,name = \"A1_layer2\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "A1_net = A1_layer2(A1_layer1(A1_input))\n",
    "\n",
    "B_input = Input(shape=(MAX_SENT_LENGTH,EMBED_DIM))\n",
    "\n",
    "B_layer1 = LSTM(EMBED_DIM-25,name = \"B_layer1\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "B_layer2 = LSTM(EMBED_DIM-50,name = \"B_layer2\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "\n",
    "B_net = B_layer2(B_layer1(B_input))\n",
    "\n",
    "combined = concatenate([A1_net,B_net])\n",
    "A2_pred1 = LSTM(EMBED_DIM, name = \"A2_layer1\", return_sequences = True, dropout = LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "A2_pred2 = LSTM(EMBED_DIM, name = \"A2_layer2\", return_sequences = True, dropout = LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "#A2_pred3 = LSTM(EMBED_DIM, name = \"A2_layer3\", return_sequences = True, dropout = LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "\n",
    "A2_net =A2_pred2(A2_pred1(combined))\n",
    "\n",
    "chat_model = Model(inputs = [ A1_input,B_input], outputs = [A2_net])\n",
    "chat_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint( 'chat_net.h5',verbose = 1,monitor = 'val_acc',save_best_only = True)\n",
    "early_stopping = EarlyStopping( monitor = 'val_acc',patience = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr = 0.0015)\n",
    "chat_model.compile( optimizer=adam,loss = null_punisher,metrics = ['accuracy'])\n",
    "chat_model.load_weights('chat_net.h5',by_name = True)\n",
    "for a1,b,a2 in sets:\n",
    "    A1_train,B_train,A2_train = w2v.get_training_data(a1,b,a2)\n",
    "    chat_model.fit([A1_train,B_train], A2_train,\n",
    "          batch_size=200, epochs=3,\n",
    "          validation_split = 0.05,\n",
    "          callbacks = [checkpointer,early_stopping] )\n",
    "    #chat_model.save('chat_net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def just_model_un_vectorize( predicted ):\n",
    "    ret =[]\n",
    "    for word_vec in predicted:\n",
    "        if abs(word_vec[-1] - 1) < 0.001:\n",
    "            ret.append(\"_\")\n",
    "            continue\n",
    "        word_vec = word_vec[:-1]\n",
    "        x = w2v_model.similar_by_vector( word_vec, topn = 3 )\n",
    "        print( x )\n",
    "        w2v_word,w2v_similarity = x[0]\n",
    "        print( w2v_word, \" \", w2v_similarity )\n",
    "        ret.append(w2v_word)\n",
    "    return( \" \".join(ret) )\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 8 1 @ I'll slip in , talk them into to come out , and you'll be free to blow holy high heaven the whole lot of them .\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v.unvectorize_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = chat_model.predict([A1_test,B_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_words = just_model_un_vectorize( predicted[0] )\n",
    "print( predicted_words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model.most_similar('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = {}\n",
    "a['__BLANK__'] = BLANK\n",
    "a['__BLANK__']\n",
    "\n",
    "import pickle\n",
    "with open('unknown_words_stored.pkl', 'w+') as f:\n",
    "    pickle.dump(a, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print( A1[30000], B[30000],A2[30000] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model.similar_by_word(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AB_Input = Input(shape =(MAX_SENT_LENGTH,EMBED_DIM))\n",
    "\n",
    "AB_layer1 = LSTM(EMBED_DIM,return_sequences=True, name = \"AB_layer1\", dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "AB_layer2 = LSTM(EMBED_DIM,return_sequences=True, name = \"AB_layer2\", dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "AB_layer3 = LSTM(EMBED_DIM,return_sequences=True, name = \"AB_layer3\", dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "\n",
    "AB_output = AB_layer3(AB_layer2(AB_layer1(AB_Input)))\n",
    "\n",
    "chat_model = Model(inputs = [ AB_Input], outputs = [AB_output])\n",
    "chat_model.compile(loss=null_punisher,\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "early_stopping = EarlyStopping( monitor = 'val_acc',patience = 2)\n",
    "chat_model.load_weights('chat_net.h5',by_name=True)\n",
    "chat_model.fit([A1B_train], A2_train,\n",
    "          batch_size=200, epochs=20,\n",
    "          validation_split = 0.025 )\n",
    "chat_model.save('chat_net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_input = Input(shape=(MAX_SENT_LENGTH,EMBED_DIM))\n",
    "\n",
    "layer1 = Bidirectional(LSTM(EMBED_DIM,name = \"layer1\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT))\n",
    "layer2 = Bidirectional(LSTM(EMBED_DIM,name = \"layer2\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT))\n",
    "layer3 = LSTM(EMBED_DIM,name = \"layer3\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "\n",
    "my_output = layer3(layer2(layer1(my_input)))\n",
    "\n",
    "simpl_chat_model = Model(inputs = [ my_input], outputs = [my_output])\n",
    "simpl_chat_model.summary()\n",
    "\n",
    "simpl_checkpointer = ModelCheckpoint( 'simpl_chat_net.h5',verbose = 1,monitor = 'val_acc',save_best_only = True)\n",
    "simpl_early_stopping = EarlyStopping( monitor = 'val_acc',patience = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr = 0.02)\n",
    "simpl_chat_model.compile( optimizer=adam,loss = null_punisher,metrics = ['accuracy'])\n",
    "#simpl_chat_model.load_weights('simpl_chat_net.h5',by_name = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for a1,b,a2 in sets:\n",
    "    A1_train,B_train,A2_train = w2v.get_training_data(a1,b,a2)\n",
    "    simpl_chat_model.fit([A1_train], B_train,\n",
    "          batch_size=200, epochs=1,\n",
    "          validation_split = 0.05,\n",
    "          callbacks = [simpl_checkpointer,simpl_early_stopping] )\n",
    "    simpl_chat_model.fit([B_train], A2_train,\n",
    "          batch_size=200, epochs=1,\n",
    "          validation_split = 0.05,\n",
    "          callbacks = [simpl_checkpointer,simpl_early_stopping] )\n",
    "    #chat_model.save('chat_net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predit = simpl_chat_model.predict([B_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_words = just_model_un_vectorize( predit[0] )\n",
    "print( predicted_words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_9 (InputLayer)             (None, 30, 101)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_10 (InputLayer)            (None, 30, 101)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional)  (None, 30, 202)       164024                                       \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional) (None, 30, 202)       164024                                       \n",
      "____________________________________________________________________________________________________\n",
      "A1_layer2 (LSTM)                 (None, 30, 202)       327240                                       \n",
      "____________________________________________________________________________________________________\n",
      "B_layer2 (LSTM)                  (None, 30, 202)       327240                                       \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 30, 404)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "A2_layer1 (LSTM)                 (None, 30, 404)       1307344                                      \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistribu (None, 30, 10003)     4051215                                      \n",
      "====================================================================================================\n",
      "Total params: 6,341,087\n",
      "Trainable params: 6,341,087\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "############### One Hot ####################\n",
    "A1_input = Input(shape=(MAX_SENT_LENGTH,EMBED_DIM))\n",
    "\n",
    "A1_layer1 = Bidirectional( LSTM(EMBED_DIM,name = \"A1_layer1\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT) )\n",
    "A1_layer2 = LSTM(EMBED_DIM*2,name = \"A1_layer2\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "A1_net = A1_layer2(A1_layer1(A1_input))\n",
    "\n",
    "B_input = Input(shape=(MAX_SENT_LENGTH,EMBED_DIM))\n",
    "\n",
    "B_layer1 = Bidirectional( LSTM(EMBED_DIM,name = \"B_layer1\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT) )\n",
    "B_layer2 = LSTM(EMBED_DIM*2,name = \"B_layer2\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "\n",
    "B_net = B_layer2(B_layer1(B_input))\n",
    "\n",
    "combined = concatenate([A1_net,B_net])\n",
    "A2_pred1 = LSTM(EMBED_DIM*4, name = \"A2_layer1\", return_sequences = True, dropout = LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "A2_pred2 = TimeDistributed(Dense(VOCAB_SIZE + 3, name = \"A2_layer2\", activation = 'softmax' ) )\n",
    "\n",
    "A2_net =A2_pred2(A2_pred1(combined))\n",
    "\n",
    "one_hot_chat_model = Model(inputs = [ A1_input,B_input], outputs = [A2_net])\n",
    "one_hot_chat_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint( 'one_hot_chat_net.h5',verbose = 1,monitor = 'val_categorical_accuracy',save_best_only = True)\n",
    "early_stopping = EarlyStopping( monitor = 'val_categorical_accuracy',patience = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sets = get_sets_of_data(size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "adam = keras.optimizers.Adam(lr = 0.025)#default 0.001\n",
    "one_hot_chat_model.compile( optimizer=adam,loss = 'categorical_crossentropy',metrics = ['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 950 samples, validate on 50 samples\n",
      "Epoch 1/5\n",
      "950/950 [==============================] - 68s - loss: 1.2043 - categorical_accuracy: 0.6977 - val_loss: 0.3828 - val_categorical_accuracy: 0.8293\n",
      "Epoch 2/5\n",
      "950/950 [==============================] - 74s - loss: 0.3426 - categorical_accuracy: 0.8442 - val_loss: 0.3326 - val_categorical_accuracy: 0.8420\n",
      "Epoch 3/5\n",
      "950/950 [==============================] - 71s - loss: 0.3728 - categorical_accuracy: 0.8329 - val_loss: 0.3734 - val_categorical_accuracy: 0.8360\n",
      "Epoch 4/5\n",
      "950/950 [==============================] - 71s - loss: 0.3422 - categorical_accuracy: 0.8431 - val_loss: 0.3473 - val_categorical_accuracy: 0.8487\n",
      "Epoch 5/5\n",
      "950/950 [==============================] - 75s - loss: 0.3143 - categorical_accuracy: 0.8542 - val_loss: 0.4893 - val_categorical_accuracy: 0.7967\n",
      "Train on 950 samples, validate on 50 samples\n",
      "Epoch 1/5\n",
      "950/950 [==============================] - 72s - loss: 0.3996 - categorical_accuracy: 0.8189 - val_loss: 0.3137 - val_categorical_accuracy: 0.8513\n",
      "Epoch 2/5\n",
      "950/950 [==============================] - 68s - loss: 0.3280 - categorical_accuracy: 0.8445 - val_loss: 0.2898 - val_categorical_accuracy: 0.8687\n",
      "Epoch 3/5\n",
      "950/950 [==============================] - 67s - loss: 0.3479 - categorical_accuracy: 0.8348 - val_loss: 0.2948 - val_categorical_accuracy: 0.8613\n",
      "Epoch 4/5\n",
      "950/950 [==============================] - 69s - loss: 0.3225 - categorical_accuracy: 0.8473 - val_loss: 0.3473 - val_categorical_accuracy: 0.8447\n",
      "Epoch 5/5\n",
      "950/950 [==============================] - 69s - loss: 0.3409 - categorical_accuracy: 0.8405 - val_loss: 0.3097 - val_categorical_accuracy: 0.8547\n",
      "Train on 950 samples, validate on 50 samples\n",
      "Epoch 1/5\n",
      "950/950 [==============================] - 68s - loss: 0.3367 - categorical_accuracy: 0.8401 - val_loss: 0.3675 - val_categorical_accuracy: 0.8373\n",
      "Epoch 2/5\n",
      "950/950 [==============================] - 70s - loss: 0.3293 - categorical_accuracy: 0.8475 - val_loss: 0.3528 - val_categorical_accuracy: 0.8400\n",
      "Epoch 3/5\n",
      "950/950 [==============================] - 68s - loss: 0.3433 - categorical_accuracy: 0.8449 - val_loss: 0.5084 - val_categorical_accuracy: 0.8080\n",
      "Epoch 4/5\n",
      "950/950 [==============================] - 68s - loss: 0.3651 - categorical_accuracy: 0.8406 - val_loss: 0.3850 - val_categorical_accuracy: 0.8300\n",
      "Epoch 5/5\n",
      "950/950 [==============================] - 64s - loss: 0.3209 - categorical_accuracy: 0.8481 - val_loss: 0.4452 - val_categorical_accuracy: 0.7900\n",
      "Train on 950 samples, validate on 50 samples\n",
      "Epoch 1/5\n",
      "950/950 [==============================] - 65s - loss: 0.3755 - categorical_accuracy: 0.8226 - val_loss: 0.4131 - val_categorical_accuracy: 0.8100\n",
      "Epoch 2/5\n",
      "950/950 [==============================] - 66s - loss: 0.3318 - categorical_accuracy: 0.8434 - val_loss: 0.3473 - val_categorical_accuracy: 0.8360\n",
      "Epoch 3/5\n",
      "950/950 [==============================] - 64s - loss: 0.3378 - categorical_accuracy: 0.8395 - val_loss: 0.3717 - val_categorical_accuracy: 0.8227\n",
      "Epoch 4/5\n",
      "950/950 [==============================] - 65s - loss: 0.3512 - categorical_accuracy: 0.8379 - val_loss: 0.3742 - val_categorical_accuracy: 0.8127\n",
      "Epoch 5/5\n",
      "950/950 [==============================] - 67s - loss: 0.3327 - categorical_accuracy: 0.8420 - val_loss: 0.4643 - val_categorical_accuracy: 0.8013\n",
      "Train on 950 samples, validate on 50 samples\n",
      "Epoch 1/5\n",
      "950/950 [==============================] - 68s - loss: 0.3835 - categorical_accuracy: 0.8202 - val_loss: 0.3706 - val_categorical_accuracy: 0.8153\n",
      "Epoch 2/5\n",
      "950/950 [==============================] - 66s - loss: 0.3426 - categorical_accuracy: 0.8400 - val_loss: 0.2997 - val_categorical_accuracy: 0.8627\n",
      "Epoch 3/5\n",
      "950/950 [==============================] - 70s - loss: 0.3403 - categorical_accuracy: 0.8382 - val_loss: 0.2926 - val_categorical_accuracy: 0.8633\n",
      "Epoch 4/5\n",
      "950/950 [==============================] - 69s - loss: 0.3215 - categorical_accuracy: 0.8479 - val_loss: 0.3215 - val_categorical_accuracy: 0.8540\n",
      "Epoch 5/5\n",
      "950/950 [==============================] - 66s - loss: 0.3724 - categorical_accuracy: 0.8290 - val_loss: 0.3379 - val_categorical_accuracy: 0.8273\n",
      "Train on 950 samples, validate on 50 samples\n",
      "Epoch 1/5\n",
      "950/950 [==============================] - 65s - loss: 0.3381 - categorical_accuracy: 0.8396 - val_loss: 0.3679 - val_categorical_accuracy: 0.8173\n",
      "Epoch 2/5\n",
      "950/950 [==============================] - 66s - loss: 0.3280 - categorical_accuracy: 0.8433 - val_loss: 0.3288 - val_categorical_accuracy: 0.8447\n",
      "Epoch 3/5\n",
      "950/950 [==============================] - 66s - loss: 0.3307 - categorical_accuracy: 0.8380 - val_loss: 0.3598 - val_categorical_accuracy: 0.8227\n",
      "Epoch 4/5\n",
      "950/950 [==============================] - 66s - loss: 0.3183 - categorical_accuracy: 0.8508 - val_loss: 0.3388 - val_categorical_accuracy: 0.8387\n",
      "Epoch 5/5\n",
      "950/950 [==============================] - 66s - loss: 0.3455 - categorical_accuracy: 0.8399 - val_loss: 0.3617 - val_categorical_accuracy: 0.8487\n",
      "Train on 950 samples, validate on 50 samples\n",
      "Epoch 1/5\n",
      "950/950 [==============================] - 67s - loss: 0.3677 - categorical_accuracy: 0.8279 - val_loss: 0.4142 - val_categorical_accuracy: 0.7953\n",
      "Epoch 2/5\n",
      "950/950 [==============================] - 68s - loss: 0.3899 - categorical_accuracy: 0.8232 - val_loss: 0.3806 - val_categorical_accuracy: 0.8407\n",
      "Epoch 3/5\n",
      "200/950 [=====>........................] - ETA: 58s - loss: 0.3652 - categorical_accuracy: 0.8292"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-1f07ffede8b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m           \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m           callbacks = [] )#checkpointer,early_stopping] )\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mone_hot_chat_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'one_hot_chat_net.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "one_hot_chat_model.load_weights('one_hot_chat_net.h5',by_name = True)\n",
    "i = 0\n",
    "for a1,b,a2 in sets:\n",
    "    if i < 7:\n",
    "        i += 1\n",
    "        continue\n",
    "    A1_train,B_train,A2_train = w2v.get_training_data_one_hot_out(a1,b,a2)\n",
    "    cat_a2 = []\n",
    "    for sent in A2_train:\n",
    "        cat_a2.append(to_categorical(sent,num_classes = VOCAB_SIZE + 3).astype('int8'))\n",
    "    cat_a2 = np.array(cat_a2)\n",
    "    one_hot_chat_model.fit([A1_train,B_train], cat_a2,\n",
    "          batch_size=50, epochs=5,\n",
    "          validation_split = 0.05,\n",
    "          callbacks = [] )#checkpointer,early_stopping] )\n",
    "    one_hot_chat_model.save('one_hot_chat_net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_vectorize( sentence, pad_length = -1, word_freqs = None ):\n",
    "    if word_freqs is None:\n",
    "        word_freqs = np.load('words_in_order_of_freq.npy')\n",
    "    \n",
    "    sentence = split_sentence( sentence )\n",
    "    words = sentence.split(\" \")\n",
    "    vectorized_sentence = []\n",
    "    \n",
    "    for word in words:\n",
    "        lower_word = word.lower()\n",
    "        number = word_freqs.index(lower_word)\n",
    "        if number > VOCAB_SIZE:\n",
    "            number = UNK\n",
    "        vectorized_sentence.append( number )\n",
    "\n",
    "    if( pad_length != -1 ):\n",
    "        while( len(vectorized_sentence) < pad_length ):\n",
    "            vectorized_sentence.append(NULL)\n",
    "    \n",
    "    return np.array(vectorized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 10003)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(A2_train[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 10003)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 30)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqs = np.load('words_in_order_of_freq.npy') \n",
    "\n",
    "def get_random_test_sentence():\n",
    "    index = random.randint(0,len(A1)-1)\n",
    "    print A1[index]\n",
    "    print B[index]\n",
    "    print A2[index]\n",
    "    return( w2v.get_training_data_one_hot_out(A1[index:index+1],B[index:index+1],A2[index:index+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 8 1 @ ME ? ! No , uh , I'm just a transvestite .\n",
      "1 9 1 @ Isn't that the same thing ?\n",
      "2 8 1 @ No , no ! I like girls . So how 'bout Friday ?\n"
     ]
    }
   ],
   "source": [
    "A1_test,B_test,A2_test = get_random_test_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = one_hot_chat_model.predict([A1_test,B_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prizes prizes prizes prizes prizes prizes prizes prizes prizes prizes prizes prizes prizes prizes prizes prizes poolroom poolroom poolroom poolroom poolroom poolroom poolroom poolroom poolroom poolroom poolroom poolroom poolroom poolroom\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_words = []\n",
    "for word_vec in predict[0]:\n",
    "    #print(word_vec )\n",
    "    pred_words.append( word_freqs[np.where(word_vec==max(word_vec))[0][0]] )\n",
    "print( \" \".join(pred_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    one_hot_chat_model.save('one_hot_chat_net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
